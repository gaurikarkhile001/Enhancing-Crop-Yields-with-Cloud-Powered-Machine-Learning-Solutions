{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature        ph    rainfall label\n",
      "0  90  42  43    20.879744  6.502985  202.935536  rice\n",
      "1  85  58  41    21.770462  7.038096  226.655537  rice\n",
      "2  60  55  44    23.004459  7.840207  263.964248  rice\n",
      "3  74  35  40    26.491096  6.980401  242.864034  rice\n",
      "4  78  42  42    20.130175  7.628473  262.717340  rice\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('crop_reccomedations.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature        ph    rainfall label\n",
      "0  90  42  43    20.879744  6.502985  202.935536  rice\n",
      "1  85  58  41    21.770462  7.038096  226.655537  rice\n",
      "2  60  55  44    23.004459  7.840207  263.964248  rice\n",
      "3  74  35  40    26.491096  6.980401  242.864034  rice\n",
      "4  78  42  42    20.130175  7.628473  262.717340  rice\n",
      "Training and testing datasets have been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('crop_reccomedations.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and label\n",
    "X = data[['N', 'P', 'K', 'temperature', 'ph', 'rainfall']]\n",
    "y = data['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Combine the features and labels back into dataframes\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save the training and testing datasets\n",
    "train_data.to_csv('train_crop_recommendation.csv', index=False)\n",
    "test_data.to_csv('test_crop_recommendation.csv', index=False)\n",
    "\n",
    "print(\"Training and testing datasets have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized training dataset has been saved and scaler has been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the training dataset\n",
    "train_data = pd.read_csv('train_crop_recommendation.csv')\n",
    "\n",
    "# Separate features and label\n",
    "X_train = train_data[['N', 'P', 'K', 'temperature', 'ph', 'rainfall']]\n",
    "y_train = train_data['label']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Combine the scaled features with the labels\n",
    "train_data_scaled = pd.DataFrame(X_train_scaled, columns=['N', 'P', 'K', 'temperature', 'ph', 'rainfall'])\n",
    "train_data_scaled['label'] = y_train.values\n",
    "\n",
    "# Save the standardized training dataset\n",
    "train_data_scaled.to_csv('train_crop_recommendation_scaled.csv', index=False)\n",
    "\n",
    "# Optionally, you can save the scaler to use it later on the test data or new data\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Standardized training dataset has been saved and scaler has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized testing dataset has been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the testing dataset\n",
    "test_data = pd.read_csv('test_crop_recommendation.csv')\n",
    "\n",
    "# Separate features and label\n",
    "X_test = test_data[['N', 'P', 'K', 'temperature', 'ph', 'rainfall']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Load the previously saved scaler (fitted on training data)\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Combine the scaled features with the labels\n",
    "test_data_scaled = pd.DataFrame(X_test_scaled, columns=['N', 'P', 'K', 'temperature', 'ph', 'rainfall'])\n",
    "test_data_scaled['label'] = y_test.values\n",
    "\n",
    "# Save the standardized testing dataset\n",
    "test_data_scaled.to_csv('test_crop_recommendation_scaled.csv', index=False)\n",
    "\n",
    "print(\"Standardized testing dataset has been saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
