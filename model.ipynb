{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.8259\n",
      "Naive Bayes: 0.8596\n",
      "Support Vector Machine: 0.8477\n",
      "K-Nearest Neighbor: 0.9596\n",
      "Decision Tree: 0.9989\n",
      "Random Forest: 0.9989\n",
      "AdaBoost: 0.2957\n",
      "Gradient Boosting: 0.9968\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the training dataset\n",
    "train_data = pd.read_csv('train_crop_recommendation_scaled.csv')\n",
    "\n",
    "# Separate features and label\n",
    "X_train = train_data[['N', 'P', 'K', 'temperature', 'ph', 'rainfall']]\n",
    "y_train = train_data['label']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbor': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    \n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_train_scaled)\n",
    "    accuracy = accuracy_score(y_train, predictions)\n",
    "    results[name] = accuracy\n",
    "\n",
    "# Display the results\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f'{model_name}: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.8116\n",
      "Naive Bayes Test Accuracy: 0.8600\n",
      "Support Vector Machine Test Accuracy: 0.8436\n",
      "K-Nearest Neighbor Test Accuracy: 0.9322\n",
      "Decision Tree Test Accuracy: 0.9702\n",
      "Random Forest Test Accuracy: 0.9851\n",
      "AdaBoost Test Accuracy: 0.2941\n",
      "Gradient Boosting Test Accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the training and testing datasets\n",
    "train_data = pd.read_csv('train_crop_recommendation_scaled.csv')\n",
    "test_data = pd.read_csv('test_crop_recommendation_scaled.csv')\n",
    "\n",
    "# Separate features and labels for training and testing\n",
    "X_train = train_data[['N', 'P', 'K', 'temperature', 'ph', 'rainfall']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['N', 'P', 'K', 'temperature', 'ph', 'rainfall']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Transform the testing features using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbor': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train models and evaluate on the test set\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    results[name] = accuracy\n",
    "\n",
    "# Display the results\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f'{model_name} Test Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
